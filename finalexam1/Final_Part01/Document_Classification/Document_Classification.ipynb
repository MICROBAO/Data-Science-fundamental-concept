{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Final Exam Dataset #3:  Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This task concerns about classifying text documents as class 0 or class 1. We intentionally hide the meaning of the class labels, but you \n",
    "can think of a class label as the category of an article. For example, given an article, we can classify whether that article\n",
    "is about Technology or Politics based on the words used in the article. \n",
    "\n",
    "For example, the following article can be classified as Technology news:\n",
    "<blockquote>\n",
    "<a href=\"http://technews.acm.org/archives.cfm?fo=2015-02-feb/feb-13-2015.html#773401\">\n",
    "http://technews.acm.org/archives.cfm?fo=2015-02-feb/feb-13-2015.html#773401</a>\n",
    "\n",
    "<b>With Google Glass App Developed at UCLA, Scientists Can Analyze Plants' Health in Seconds</b>\n",
    "<br/>\n",
    "(UCLA Newsroom (CA) (02/09/15) Shaun Mason)\n",
    "\n",
    "<i>\n",
    "University of California, Los Angeles (UCLA) researchers have developed a Google Glass application that enables the wearer to quickly analyze the health of a plant without damaging it. The app analyzes the concentration of chlorophyll, which indicates water, soil, and air quality. Conventional methods for measuring chlorophyll concentration involve removing some of the plant's leaves, dissolving them in a chemical solvent, and then performing the chemical analysis. With the new Google Glass app, leaves are examined and then left functional and intact. The system relies on an image captured by the Google Glass camera to measure the chlorophyll's light absorption in the green part of the optical spectrum. The system also has a handheld illuminator unit that can be produced using three-dimensional printing. The user controls the device with the Google Glass touch control pad or with the voice command feature. The system photographs the leaf and wirelessly sends an enhanced image to a remote server, which processes the data from the image and sends back a chlorophyll concentration reading in less than 10 seconds. \"This will allow a scientist to get readings walking from plant to plant in a field of crops, or look at many different plants in a drought-plagued area and accumulate plant health data very quickly,\" says UCLA professor Aydogan Ozcan.\n",
    "</i>\n",
    "</blockquote>\n",
    "One way to convert the above article into a format that we can train classifiers on is to use bag of words model. \n",
    "A good explanation of this model can be found here:\n",
    "<a href=\"http://en.wikipedia.org/wiki/Bag-of-words_model\">\n",
    "http://en.wikipedia.org/wiki/Bag-of-words_model</a>\n",
    "        \n",
    "If we apply the bag of words model to the above article, we get a dictionary:\n",
    "<pre>\n",
    "{\n",
    "    \"Google\":5,\n",
    "    \"glass\":5,\n",
    "    \"app\":3\n",
    "    ... # There are many more entries in this dictionary, but we only list the first 3 words and their frequencies\n",
    "}\n",
    "</pre>\n",
    "This means the the word \"Google\" showed up in the article 5 times, and the word \"glass\" appeared in the article 5 times. We then replace\n",
    "\"Google\" by the feature number 1, \"glass\" by feature number 2, and \"app\" by feature number 3\n",
    "to get the following entry to represent this text document:\n",
    "<blockquote>\n",
    "1:5 2:5 3:3  ... # with many more entries in this document, but we only list the first 3\n",
    "</blockquote>\n",
    "If we assign this document a class label 0 (to represent technology),\n",
    "then we can get a text document in the training set as:\n",
    "<blockquote>\n",
    "0 1:5 2:5 3:3 ... # with many more entries in this document, but we only list the first 3\n",
    "</blockquote>\n",
    "to represent this article.\n",
    "\n",
    "Thus, given the attached training set with 417852 text documents in 2 categories (class 0 and class 1), you are to build a model \n",
    "(or as an ensemble of models) your goal is to classify the test set (with 32301 text documents) as accurately as possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Tutorial on converting raw text data into a Bag of Words.\n",
    "\n",
    "If you want to learn how to use Python to convert raw data into a bag of words, please reference the following link:\n",
    "https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>To simplify this assignment, we have already converted the raw data from articles for you.</b>  However, this article explains how the data was generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample code to solve this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(417852, 802934)\n",
      "(417852,)\n",
      "(32301, 802934)\n",
      "(32301,)\n"
     ]
    }
   ],
   "source": [
    "# We first load the data using the Python library \n",
    "from sklearn.datasets import load_svmlight_file\n",
    "import numpy as np\n",
    "\n",
    "# You might want to specify the exact path to locate your input files\n",
    "# Say, \"C:\\\\cs249\\\\train.txt\" for Windows users.\n",
    "\n",
    "x_train, y_train = load_svmlight_file(\"train.txt\")\n",
    "x_test, y_test = load_svmlight_file(\"test.txt\")\n",
    "\n",
    "print(x_train.shape)  # should output (417852, 802934)\n",
    "print(y_train.shape)  # should output (417852,)\n",
    "print(x_test.shape)   # should output (32301, 802934)\n",
    "print(y_test.shape)   # should output (32301,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_train holds the training set without the class labels.\n",
    "y_train holds the class labels for the training set.\n",
    "\n",
    "x_test holds the test set without the test labels.\n",
    "y_test holds the class labels for the test set.\n",
    "\n",
    "However, we've assigned -1 to all the class labels for test set.  Your job is to develop a classifier that predicts correct class labels for the test set.\n",
    "\n",
    "x_train.shape shows the dimension of the text datasets. \n",
    "In this dataset, the training set has 417852 training examples with 802934 words. \n",
    "\n",
    "A challenge in this dataset is that it is stored in sparse matrix format instead of dense matrix format. For example, the \n",
    "first row of the training set is:\n",
    "\n",
    "0 188:1 13191:1 118098:1\n",
    "\n",
    "This means that this text document only has word 188, word 13191, and word 118098 present (after removing stopwords like \"a\", \"the\", \"as\", ...etc). If we represent this in dense matrix format, we will have 802931 zeros in this row:\n",
    "\n",
    "[0,0,...0,1,0,...,0,1,0,...,0,1,0,..,0] \n",
    "\n",
    "Storing 802931 zeros and 3 ones wastes a lot of memory, so in the literature, people solve this problem by only storeing the word and its frequencies in a sparse matrix format:\n",
    "\n",
    "0 188:1 13191:1 118098:1\n",
    "\n",
    "Unfortunately, not all the machine learning libraries in scikit-learn support the use of sparse matrices.\n",
    "Below is a list of libraries that should be able to work with sparse matrix format:\n",
    "<pre>\n",
    "svm.SVR()\n",
    "svm.NuSVR()\n",
    "naive_bayes.BernoulliNB().\n",
    "naive_bayes.MultinomialNB()\n",
    "neighbors.KNeighborsRegressor()\n",
    "linear_model.ElasticNet()\n",
    "linear_model.PassiveAggressiveRegressor()\n",
    "linear_model.PassiveAggressiveClassifier()\n",
    "linear_model.Perceptron()\n",
    "linear_model.Ridge()\n",
    "linear_model.Lasso()\n",
    "linear_model.LinearRegression()\n",
    "linear_model.LogisticRegression()\n",
    "linear_model.SGDClassifier()\n",
    "linear_model.SGDRegressor()\n",
    "</pre>\n",
    "There might be other libraries that can work with sparse matrix format though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[262154,  15223],\n",
       "       [ 22006, 118469]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since we have the training data, we can use NaiveBayes to train our classifier.\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "clf_NB = MultinomialNB()\n",
    "clf_NB.fit(x_train, y_train)\n",
    "y_train_pred_NB = clf_NB.predict(x_train)\n",
    "confusion_matrix(y_train, y_train_pred_NB) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91090386069708895"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, y_train_pred_NB) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the training accuracy is 91.09%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#What your program's output should look like\n",
    "\n",
    "Your program should output 32301 lines consisting of 0s and 1s for the prediction labels for the test set like:\n",
    "<pre>\n",
    "0\n",
    "0\n",
    "1\n",
    "...\n",
    "1\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to format your output correctly for Mooshak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you can use the following code to generate output that is acceptable by Mooshak:\n",
    "\n",
    "# generate the test labels\n",
    "y_test_pred_NB = clf_NB.predict(x_test)                    \n",
    "\n",
    "output_str = \"\\n\".join(map(str,y_test_pred_NB.astype(int))) \n",
    "\n",
    "# You might want to specify the exact path to output your text file\n",
    "# Say, \"C:\\\\cs249\\\\output_label.txt\" for Windows users.\n",
    "f = open('output_label.txt', 'w') \n",
    "\n",
    "f.write(output_str);\n",
    "f.close()\n",
    "\n",
    "# Then submit the .txt file to Mooshak"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
