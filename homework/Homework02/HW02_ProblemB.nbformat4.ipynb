{"metadata": {"language_info": {"codemirror_mode": {"name": "ipython", "version": 2}, "nbconvert_exporter": "python", "file_extension": ".py", "version": "2.7.9", "mimetype": "text/x-python", "name": "python", "pygments_lexer": "ipython2"}, "kernelspec": {"name": "python2", "language": "python", "display_name": "Python 2"}}, "nbformat": 4, "nbformat_minor": 0, "cells": [{"metadata": {}, "cell_type": "markdown", "source": "#HW2 Problem:  LDA and QDA"}, {"metadata": {}, "cell_type": "markdown", "source": "Problem:  given a tabular dataset of feature values $X$ and classes $\\boldsymbol{y}$, derive both LDA and QDA models, and determine how accurate they are.\n\nMore specifically, develop a program that reads in a numeric table with X and y from stdin, determines the normal distribution parameters for X, and derive the LDA and QDA models described in Chapter 2 of Murphy's book.\n\nThe columns of $X$ should all be numeric.  The values in the last column, $\\boldsymbol{y}$,\ncan be either symbolic or numeric.\nFor example, with the <tt>iris</tt> dataset, the last column is symbolic.\n\nYour program should print the \"confusion matrix\" for LDA, and for QDA.\n\nIf there are $k$ different classes, the confusion matrix is a $k \\times k$ table\nwhose $i,j$-th entry is the number of times that an input row $\\boldsymbol{x}$\nwas classified (by LDA or QDA) as being in class $i$, when in fact its $y$ value is $j$.\n\nYour program should print the confusion matrices both for LDA and for QDA.\nFor example, with the iris dataset (as described below) the confusion matrices are 3x3, and your output should look like this:\n\n<pre>\n50 0 0\n0 48 1\n0 2 49\n50 0 0\n0 48 1\n0 2 49\n</pre>\n\nThere are implementations of LDA and QDA in the MASS package, and you can use them.\n\n\n"}, {"metadata": {"collapsed": false, "trusted": false}, "outputs": [], "source": "### %load_ext rmagic\n### import rpy2 as Rpy\n\n%load_ext rpy2.ipython\n\n# new feature -- ipython is now part of rpy2.", "cell_type": "code", "execution_count": 61}, {"metadata": {}, "cell_type": "markdown", "source": "##  Centroids of the 3 classes in the iris dataset\n\nThe $X$ matrix is of size $150 \\times 4$, with 4 features\n(Sepal Length, Sepal Width, Petal Length, Petal Width). The $150 \\times 1$ vector $\\boldsymbol{y}$ gives classes for these irises.\nEach of the 3 classes has 50 observations.\n\nWe can compute the centroids of each class (means of each gaussian) using R.\n"}, {"metadata": {"collapsed": false, "trusted": false}, "outputs": [{"metadata": {}, "data": {"text/plain": "INDICES: 1\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.300   Min.   :1.000   Min.   :0.100  \n 1st Qu.:4.800   1st Qu.:3.200   1st Qu.:1.400   1st Qu.:0.200  \n Median :5.000   Median :3.400   Median :1.500   Median :0.200  \n Mean   :5.006   Mean   :3.428   Mean   :1.462   Mean   :0.246  \n 3rd Qu.:5.200   3rd Qu.:3.675   3rd Qu.:1.575   3rd Qu.:0.300  \n Max.   :5.800   Max.   :4.400   Max.   :1.900   Max.   :0.600  \n------------------------------------------------------------ \nINDICES: 2\n  Sepal.Length    Sepal.Width     Petal.Length   Petal.Width   \n Min.   :4.900   Min.   :2.000   Min.   :3.00   Min.   :1.000  \n 1st Qu.:5.600   1st Qu.:2.525   1st Qu.:4.00   1st Qu.:1.200  \n Median :5.900   Median :2.800   Median :4.35   Median :1.300  \n Mean   :5.936   Mean   :2.770   Mean   :4.26   Mean   :1.326  \n 3rd Qu.:6.300   3rd Qu.:3.000   3rd Qu.:4.60   3rd Qu.:1.500  \n Max.   :7.000   Max.   :3.400   Max.   :5.10   Max.   :1.800  \n------------------------------------------------------------ \nINDICES: 3\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.900   Min.   :2.200   Min.   :4.500   Min.   :1.400  \n 1st Qu.:6.225   1st Qu.:2.800   1st Qu.:5.100   1st Qu.:1.800  \n Median :6.500   Median :3.000   Median :5.550   Median :2.000  \n Mean   :6.588   Mean   :2.974   Mean   :5.552   Mean   :2.026  \n 3rd Qu.:6.900   3rd Qu.:3.175   3rd Qu.:5.875   3rd Qu.:2.300  \n Max.   :7.900   Max.   :3.800   Max.   :6.900   Max.   :2.500  \n"}, "output_type": "display_data"}], "source": "%%R\n\ndata(iris)\n\nX = data.matrix(iris[,1:4]) #  equivalently:  X = data.matrix(iris[, -5 ])\ny = unclass(iris[,5])       #  equivalently:  y = unclass(iris$Species)\n\n# print summary statistics for each kind of iris\n\nprint( by( X, y, summary ) )  # summarizes the subsets of X \"grouped by\" y\n\n# the Mean values in these summaries give the centroids of each cluster/MVN\n", "cell_type": "code", "execution_count": 62}, {"metadata": {"collapsed": false, "trusted": false}, "outputs": [{"metadata": {}, "data": {"text/plain": "setosa \nSepal.Length  Sepal.Width Petal.Length  Petal.Width \n       5.006        3.428        1.462        0.246 \nversicolor \nSepal.Length  Sepal.Width Petal.Length  Petal.Width \n       5.936        2.770        4.260        1.326 \nvirginica \nSepal.Length  Sepal.Width Petal.Length  Petal.Width \n       6.588        2.974        5.552        2.026 \n"}, "output_type": "display_data"}], "source": "%%R\n\n# printing only the mean value/centroid for each class\n\nclasses = as.character( unique(iris$Species) )\nk = length(classes)\n\nfor (j in 1:k) {\n    cat( classes[j], \"\\n\" )\n    Xc = subset( X, (y == j) )\n    print( apply(Xc, 2, mean) ) # vector of means for each column\n}", "cell_type": "code", "execution_count": 63}, {"metadata": {}, "cell_type": "markdown", "source": "##  Sample use of LDA and QDA -- with the iris dataset\n\nThe $X$ matrix is of size $150 \\times 4$, with 4 features\n(Sepal Length, Sepal Width, Petal Length, Petal Width).\nThus each column in this dataset is a random sample from a different distribution,\nbut they are nontrivially correlated.\n\nThe $150 \\times 1$ vector $\\boldsymbol{y}$ gives classes for these irises.\nEach of the 3 classes has 50 observations.\n"}, {"metadata": {"collapsed": false, "trusted": false}, "outputs": [], "source": "%%R\n\n# load the MASS package, which includes simple implementations of LDA and QDA\n\nnot.installed <- function(pkg) !is.element(pkg, installed.packages()[,1])\n\nif (not.installed(\"MASS\"))  install.packages(\"MASS\")  # we need the MASS package\n\nlibrary(MASS)  #  load the MASS package\n\n#  ?lda      #  help for the LDA classifier\n#  ?qda      #  help for the QDA classifier\n", "cell_type": "code", "execution_count": 64}, {"metadata": {}, "cell_type": "markdown", "source": "##run LDA on the iris data"}, {"metadata": {"collapsed": false, "trusted": false}, "outputs": [{"metadata": {}, "data": {"text/plain": "\n\nCentroids of the model:\n\n  XSepal.Length XSepal.Width XPetal.Length XPetal.Width\n1         5.006        3.428         1.462        0.246\n2         5.936        2.770         4.260        1.326\n3         6.588        2.974         5.552        2.026\n\n\nScaling of the model:\n\n                     LD1         LD2\nXSepal.Length  0.8293776  0.02410215\nXSepal.Width   1.5344731  2.16452123\nXPetal.Length -2.2012117 -0.93192121\nXPetal.Width  -2.8104603  2.83918785\n\n\nWhat the model data structure looks like:\n\nList of 10\n $ prior  : Named num [1:3] 0.333 0.333 0.333\n  ..- attr(*, \"names\")= chr [1:3] \"1\" \"2\" \"3\"\n $ counts : Named int [1:3] 50 50 50\n  ..- attr(*, \"names\")= chr [1:3] \"1\" \"2\" \"3\"\n $ means  : num [1:3, 1:4] 5.01 5.94 6.59 3.43 2.77 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:3] \"1\" \"2\" \"3\"\n  .. ..$ : chr [1:4] \"XSepal.Length\" \"XSepal.Width\" \"XPetal.Length\" \"XPetal.Width\"\n $ scaling: num [1:4, 1:2] 0.8294 1.5345 -2.2012 -2.8105 0.0241 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:4] \"XSepal.Length\" \"XSepal.Width\" \"XPetal.Length\" \"XPetal.Width\"\n  .. ..$ : chr [1:2] \"LD1\" \"LD2\"\n $ lev    : chr [1:3] \"1\" \"2\" \"3\"\n $ svd    : num [1:2] 48.64 4.58\n $ N      : int 150\n $ call   : language lda(formula = y ~ X)\n $ terms  :Classes 'terms', 'formula' length 3 y ~ X\n  .. ..- attr(*, \"variables\")= language list(y, X)\n  .. ..- attr(*, \"factors\")= int [1:2, 1] 0 1\n  .. .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. .. ..$ : chr [1:2] \"y\" \"X\"\n  .. .. .. ..$ : chr \"X\"\n  .. ..- attr(*, \"term.labels\")= chr \"X\"\n  .. ..- attr(*, \"order\")= int 1\n  .. ..- attr(*, \"intercept\")= int 1\n  .. ..- attr(*, \"response\")= int 1\n  .. ..- attr(*, \".Environment\")=<environment: R_GlobalEnv> \n  .. ..- attr(*, \"predvars\")= language list(y, X)\n  .. ..- attr(*, \"dataClasses\")= Named chr [1:2] \"numeric\" \"nmatrix.4\"\n  .. .. ..- attr(*, \"names\")= chr [1:2] \"y\" \"X\"\n $ xlevels: Named list()\n - attr(*, \"class\")= chr \"lda\"\n"}, "output_type": "display_data"}], "source": "%%R\n\nX = data.matrix(iris[,1:4]) #  equivalently:  X = data.matrix(iris[, -5 ])\ny = unclass(iris[,5])       #  equivalently:  y = unclass(iris$Species)\n\nLDA.model <- lda(y ~ X)\n\n## equivalently:\n#  LDA.model <- qda(Species ~ ., iris)\n\ncat(\"\\n\\nCentroids of the model:\\n\\n\")\nprint( LDA.model$means )\n\ncat(\"\\n\\nScaling of the model:\\n\\n\")\nprint( LDA.model$scaling )\n\ncat(\"\\n\\nWhat the model data structure looks like:\\n\\n\")\nstr(LDA.model)   #  str() lets us inspect all the information in the model data structure\n", "cell_type": "code", "execution_count": 65}, {"metadata": {}, "cell_type": "markdown", "source": "## predict() is used to turn a model into a function\n\nIf $M$ is a model, and $X$ is a (possibly new) set of $X$ values, then  <b>predict(M, X)</b> yields the vector of $\\boldsymbol{y}$ values predicted by the model for the input matrix $X$.\n\nIf $M$ is a classification model, then <b>predict(M, X)</b> yields the classifications for feature vectors in the rows of $X$."}, {"metadata": {"collapsed": false, "trusted": false}, "outputs": [{"metadata": {}, "data": {"text/plain": "[1]  71  84 134\n"}, "output_type": "display_data"}], "source": "%%R\n\nLDAclassifier = function(Model,X)  {\n   predict(Model, as.data.frame(X))$class\n}\n\n# Compute the LDA predictions (\"classifications\") for each input row.\n\nLDA.classifications = LDAclassification(LDA.model, X)\n\n# Find all points whose classifications didn't agree with LDA.\n\nLDA.disagreements = (1:nrow(X))[ LDA.classifications != y ]\nprint(LDA.disagreements)  # print row numbers where LDA differed from y\n", "cell_type": "code", "execution_count": 66}, {"metadata": {"collapsed": false, "trusted": false}, "outputs": [{"metadata": {}, "data": {"text/plain": "                   y\nLDA.classifications setosa versicolor virginica\n         setosa         50          0         0\n         versicolor      0         48         1\n         virginica       0          2        49\n"}, "output_type": "display_data"}], "source": "%%R\n\n# Tabulate the number of LDA classification values vs. y values\n\nLDA.confusion.matrix = table( LDA.classifications, y )\n\nrownames( LDA.confusion.matrix ) = classes\ncolnames( LDA.confusion.matrix ) = classes\nprint( LDA.confusion.matrix )\n", "cell_type": "code", "execution_count": 67}, {"metadata": {}, "cell_type": "markdown", "source": "##Print the confusion matrix in the format required by Mooshak"}, {"metadata": {"collapsed": false, "trusted": false}, "outputs": [{"metadata": {}, "data": {"text/plain": "50 0 0 \n0 48 1 \n0 2 49 \n"}, "output_type": "display_data"}], "source": "%%R\n\nprint_matrix_for_Mooshak = function(Matrix) {\n    for (i in 1:nrow(Matrix)) {\n       cat( Matrix[i,], \"\\n\" )  # print each row as a sequence\n    }\n}\n\n\nLDA.confusion.matrix = table( LDA.classifications, y )\n\nprint_matrix_for_Mooshak( LDA.confusion.matrix )\n", "cell_type": "code", "execution_count": 68}, {"metadata": {}, "cell_type": "markdown", "source": "##run QDA on the iris data"}, {"metadata": {"collapsed": false, "trusted": false}, "outputs": [{"metadata": {}, "data": {"text/plain": "\n\nCentroids of the model:\n\n  XSepal.Length XSepal.Width XPetal.Length XPetal.Width\n1         5.006        3.428         1.462        0.246\n2         5.936        2.770         4.260        1.326\n3         6.588        2.974         5.552        2.026\n\n\nScaling of the model:\n\n, , 1\n\n                      1         2          3          4\nXSepal.Length -2.836962 -3.145110 -0.8878372 -0.4637981\nXSepal.Width   0.000000  3.938634  0.1263223 -0.2043238\nXPetal.Length  0.000000  0.000000  5.9785398 -1.7416275\nXPetal.Width   0.000000  0.000000  0.0000000 10.2978593\n\n, , 2\n\n                      1         2         3          4\nXSepal.Length -1.937342  1.197909  1.958819 -0.6910239\nXSepal.Width   0.000000 -3.746750  1.150301  2.0855780\nXPetal.Length  0.000000  0.000000 -3.389213  2.8839194\nXPetal.Width   0.000000  0.000000  0.000000 -9.3404922\n\n, , 3\n\n                     1          2          3          4\nXSepal.Length 1.572625 -0.8085097  2.6909994  0.4068814\nXSepal.Width  0.000000  3.4866013  0.0459556 -1.9279371\nXPetal.Length 0.000000  0.0000000 -3.6018203 -0.6578080\nXPetal.Width  0.000000  0.0000000  0.0000000  4.3947753\n\n\n\nWhat the model object looks like:\n\nList of 10\n $ prior  : Named num [1:3] 0.333 0.333 0.333\n  ..- attr(*, \"names\")= chr [1:3] \"1\" \"2\" \"3\"\n $ counts : Named int [1:3] 50 50 50\n  ..- attr(*, \"names\")= chr [1:3] \"1\" \"2\" \"3\"\n $ means  : num [1:3, 1:4] 5.01 5.94 6.59 3.43 2.77 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:3] \"1\" \"2\" \"3\"\n  .. ..$ : chr [1:4] \"XSepal.Length\" \"XSepal.Width\" \"XPetal.Length\" \"XPetal.Width\"\n $ scaling: num [1:4, 1:4, 1:3] -2.84 0 0 0 -3.15 ...\n  ..- attr(*, \"dimnames\")=List of 3\n  .. ..$ : chr [1:4] \"XSepal.Length\" \"XSepal.Width\" \"XPetal.Length\" \"XPetal.Width\"\n  .. ..$ : chr [1:4] \"1\" \"2\" \"3\" \"4\"\n  .. ..$ : chr [1:3] \"1\" \"2\" \"3\"\n $ ldet   : num [1:3] -13.07 -10.87 -8.93\n $ lev    : chr [1:3] \"1\" \"2\" \"3\"\n $ N      : int 150\n $ call   : language qda(formula = y ~ X)\n $ terms  :Classes 'terms', 'formula' length 3 y ~ X\n  .. ..- attr(*, \"variables\")= language list(y, X)\n  .. ..- attr(*, \"factors\")= int [1:2, 1] 0 1\n  .. .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. .. ..$ : chr [1:2] \"y\" \"X\"\n  .. .. .. ..$ : chr \"X\"\n  .. ..- attr(*, \"term.labels\")= chr \"X\"\n  .. ..- attr(*, \"order\")= int 1\n  .. ..- attr(*, \"intercept\")= int 1\n  .. ..- attr(*, \"response\")= int 1\n  .. ..- attr(*, \".Environment\")=<environment: R_GlobalEnv> \n  .. ..- attr(*, \"predvars\")= language list(y, X)\n  .. ..- attr(*, \"dataClasses\")= Named chr [1:2] \"numeric\" \"nmatrix.4\"\n  .. .. ..- attr(*, \"names\")= chr [1:2] \"y\" \"X\"\n $ xlevels: Named list()\n - attr(*, \"class\")= chr \"qda\"\n\n\nNumbers of misclassified instances with the Quadratic Discriminant:\n\n71 84 134 \n\n\n\nData for the instances misclassified with the Quadratic Discriminant:\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n71           5.9         3.2          4.8         1.8 versicolor\n84           6.0         2.7          5.1         1.6 versicolor\n134          6.3         2.8          5.1         1.5  virginica\n"}, "output_type": "display_data"}], "source": "%%R\n\nQDA.model <- qda(y ~ X)\n\n## equivalently:\n#  QDA.model <- qda(Species ~ ., iris)\n\ncat(\"\\n\\nCentroids of the model:\\n\\n\")\nprint( QDA.model$means )\n\ncat(\"\\n\\nScaling of the model:\\n\\n\")\nprint( QDA.model$scaling )\n\ncat(\"\\n\\nWhat the model object looks like:\\n\\n\")\nstr(QDA.model)   #  str() lets us inspect all the information in the model data structure\n\nQDAclassification = function(Model,X)  {\n   predict(Model,as.data.frame(X))$class\n}\n\n# find all points whose classifications didn't agree with QDA\n\ncat(\"\\n\\nNumbers of misclassified instances with the Quadratic Discriminant:\\n\\n\")\n\nQDA.disagreements = (1:nrow(X))[ QDAclassification(QDA.model, X) != y ]\ncat(QDA.disagreements, \"\\n\\n\")\n\ncat(\"\\n\\nData for the instances misclassified with the Quadratic Discriminant:\\n\\n\")\n\nprint(iris[QDA.disagreements,])\n", "cell_type": "code", "execution_count": 69}, {"metadata": {}, "cell_type": "markdown", "source": "##That's it!  Now just write an R script that does this for any dataset it reads in.\n\nTo get you started, your R script can be an extension of this outline:\n\n<pre>\n#  Read in a table (in csv format) from standard input:\nTable = read.csv( file(\"stdin\"), header=TRUE )\n\nX = data.matrix( Table[, 1:(ncol(Table)-1) ]\nclassifications = Table[, ncol(Table) ]\n\ny = unclass(classifications)  # convert the class values into numeric indices\n\nn = nrow(X)\np = ncol(X)\n\n# ... construct an LDA representation of X\n# ... determine for which rows in X the LDA classification differs from y\n# ... print the confusion matrix for LDA\n\n# ... construct a QDA representation of X\n# ... determine for which rows in X the QDA classification differs from y\n# ... print the confusion matrix for QDA\n</pre>\n\n"}, {"metadata": {}, "cell_type": "markdown", "source": "#What your program's output should look like\n\nFor example, with the iris dataset, the confusion matrices are $3 \\times 3$, and it turns out the LDA and QDA matrices are identical.\nThus the output should look like this:\n\n<pre>\n50 0 0\n0 48 1\n0 2 49\n50 0 0\n0 48 1\n0 2 49\n</pre>"}, {"metadata": {"collapsed": false, "trusted": false}, "outputs": [], "source": "", "cell_type": "code", "execution_count": null}]}